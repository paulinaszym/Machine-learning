{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\AGH\\Uczenie maszynowe\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\AGH\\Uczenie maszynowe\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cwiczenie 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Zadanie 1\n",
    "titanic = pd.read_csv('titanic3.csv')\n",
    "col_name = ['cabin','CabinReduced','sex']\n",
    "\n",
    "def f(x,col):\n",
    "    y={}  \n",
    "    c=list(set(x[col]))\n",
    "    for i, x in enumerate(c):\n",
    "        y[x] = i\n",
    "    return y\n",
    "X=[None]*3\n",
    "i=0\n",
    "for c in col_name:\n",
    "    X[i]=f(titanic,c) \n",
    "    i=i+1 \n",
    "i=0\n",
    "for c in col_name:\n",
    "    titanic[c+'_map']= titanic[c].map(X[i])    \n",
    "    i=i+1 \n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['Train_big','Test_big', 'Diff_big','Train_low', 'Test_low', 'Diff_low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadanie 2 <br>\n",
    "Random forest to algorytm, który tworzy drzewa decyzyjne na podstawie rożnych próbek danych, losowanych ze zwrotem ze zbioru treningowego. Aby uzyskać lepszą dokładność przewidywania używa on uśredniania. Losowość ma zmneijszyć wariancję estymatora lasu, jako że drzewa decyzyjne zwykle przejawiają wysoką wariancję i mają tendencję do dużego dopasowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8562385842738466 0.7767407776118579 0.816719415917359 0.8013245948786019\n"
     ]
    }
   ],
   "source": [
    "#Zadanie 3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "col_name = ['cabin_map','CabinReduced_map','sex_map']\n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic[col_name],titanic['survived'],test_size=0.3,random_state=0)\n",
    "\n",
    "col_name1 = ['cabin_map','sex_map']\n",
    "RF=RandomForestClassifier(n_estimators=220,random_state=42)\n",
    "RF.fit(X_train[col_name1],y_train)\n",
    "PredTrain=RF.predict_proba(X_train[col_name1])\n",
    "PredTest=RF.predict_proba(X_test[col_name1])\n",
    "ras = roc_auc_score(y_train, PredTrain[:,1])\n",
    "ras1 = roc_auc_score(y_test, PredTest[:,1])\n",
    "\n",
    "col_name2 = ['CabinReduced_map','sex_map']\n",
    "RF=RandomForestClassifier(n_estimators=220,random_state=42)\n",
    "RF.fit(X_train[col_name2],y_train)\n",
    "PredTrain=RF.predict_proba(X_train[col_name2])\n",
    "PredTest=RF.predict_proba(X_test[col_name2])\n",
    "ras2 = roc_auc_score(y_train, PredTrain[:,1])\n",
    "ras22 = roc_auc_score(y_test, PredTest[:,1])\n",
    "\n",
    "print(ras,ras1,ras2,ras22)\n",
    "df=df.append(pd.Series({'Train_big':ras,'Test_big':ras1,'Diff_big':ras-ras1,'Train_low':ras2,'Test_low':ras22,'Diff_low':ras2-ras22},name='RandomForestClassifier'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadanie 4<br>\n",
    "Dla danych z wysoką liczebnością cech jest większa różnica pomiędzy wynikiem dla danych treningowych a testowych. W przypadku danych o niskiej liczebności cech oba wyniki są do siebie zbliżone i są one odpowiednio niższe i większe dla danych trenignowych i testowych.<br>\n",
    "Zbyt duże dopasowanie można zaobserwować w przypadku danych o wysokiej liczebności cech. Wskazuje na to znacząca różnica pomiędzy oboma wynikami.<br>\n",
    "<br>\n",
    "Zadanie 5 <br>\n",
    "LogisticRegression to model liniowy do klasyfikacji, a nie regresji (wbrew swojej nazwie). Prawdopodobieństwo wystąpienia konkretnych wyników jest modelowane przy użyciu funkcji logistycznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7817438952596119 0.7783446712018139 0.782161528436794 0.7790083513080028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR=LogisticRegression(random_state=42)\n",
    "LR.fit(X_train[col_name1],y_train)\n",
    "PredTrain=LR.predict_proba(X_train[col_name1])\n",
    "PredTest=LR.predict_proba(X_test[col_name1])\n",
    "ras = roc_auc_score(y_train, PredTrain[:,1])\n",
    "ras1 = roc_auc_score(y_test, PredTest[:,1])\n",
    "\n",
    "LR=LogisticRegression(random_state=42)\n",
    "LR.fit(X_train[col_name2],y_train)\n",
    "PredTrain=LR.predict_proba(X_train[col_name2])\n",
    "PredTest=LR.predict_proba(X_test[col_name2])\n",
    "ras2 = roc_auc_score(y_train, PredTrain[:,1])\n",
    "ras22 = roc_auc_score(y_test, PredTest[:,1])\n",
    "\n",
    "print(ras,ras1,ras2,ras22)\n",
    "df=df.append(pd.Series({'Train_big':ras,'Test_big':ras1,'Diff_big':ras-ras1,'Train_low':ras2,'Test_low':ras22,'Diff_low':ras2-ras22},name='LogisticRegression'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla danych z dużą liczebnością cech jest bardzo mała różnica pomiędzy wynikami dla obu zbiorów, a z niską liczebnością róznica ta jest większa. Dane z dużą liczebnością mają wyższą wartość i dla danych treningowych i testowych.<br>\n",
    "<br>\n",
    "Zadanie 6<br>\n",
    "GradientBoostingClassifier w każdej fazie dopasowuje drzewa regresji na negatywnym gradiencie dwu lub wielomianowej funkcji straty. Może być używany i do binarnej i do wielo-klasowej klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8588198592123337 0.7730214036834246 0.816719415917359 0.8013245948786019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBC=GradientBoostingClassifier(n_estimators=220,random_state=42)\n",
    "GBC.fit(X_train[col_name1],y_train)\n",
    "PredTrain=GBC.predict_proba(X_train[col_name1])\n",
    "PredTest=GBC.predict_proba(X_test[col_name1])\n",
    "ras = roc_auc_score(y_train, PredTrain[:,1])\n",
    "ras1 = roc_auc_score(y_test, PredTest[:,1])\n",
    "\n",
    "GBC=GradientBoostingClassifier(n_estimators=220,random_state=42)\n",
    "GBC.fit(X_train[col_name2],y_train)\n",
    "PredTrain=GBC.predict_proba(X_train[col_name2])\n",
    "PredTest=GBC.predict_proba(X_test[col_name2])\n",
    "ras2 = roc_auc_score(y_train, PredTrain[:,1])\n",
    "ras22 = roc_auc_score(y_test, PredTest[:,1])\n",
    "\n",
    "print(ras,ras1,ras2,ras22)\n",
    "df=df.append(pd.Series({'Train_big':ras,'Test_big':ras1,'Diff_big':ras-ras1,'Train_low':ras2,'Test_low':ras22,'Diff_low':ras2-ras22},name='GradientBoostingClassifier'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla danych treningowych wyższą wartość otrzymałam dla danych o dużej liczebności cech, a dla testowych wyższa wartość jest dla tych o niskiej liczebności. Zbyt duże dopasowanie można zaobserwować w przypadku danych o dużej liczbeności cech.<br>\n",
    "<br>\n",
    "Zadanie 7<br>\n",
    "AdaBoostClassifier najpierw dopasowuje klasyfikator na oryginalnym zestawie danych, a następnie dopasowuje kopie klasyfikatora na tym samym zbiorze danyhc, zmieniając wagi źle zaklasyfikowanych przypadków."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8406729429050162 0.7759526574857585 0.8161256723642566 0.8001078480172557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ABC=AdaBoostClassifier(n_estimators=220,random_state=42)\n",
    "ABC.fit(X_train[col_name1],y_train)\n",
    "PredTrain=ABC.predict_proba(X_train[col_name1])\n",
    "PredTest=ABC.predict_proba(X_test[col_name1])\n",
    "ras = roc_auc_score(y_train, PredTrain[:,1])\n",
    "ras1 = roc_auc_score(y_test, PredTest[:,1])\n",
    "\n",
    "ABC=AdaBoostClassifier(n_estimators=220,random_state=42)\n",
    "ABC.fit(X_train[col_name2],y_train)\n",
    "PredTrain=ABC.predict_proba(X_train[col_name2])\n",
    "PredTest=ABC.predict_proba(X_test[col_name2])\n",
    "ras2 = roc_auc_score(y_train, PredTrain[:,1])\n",
    "ras22 = roc_auc_score(y_test, PredTest[:,1])\n",
    "\n",
    "print(ras,ras1,ras2,ras22)\n",
    "df=df.append(pd.Series({'Train_big':ras,'Test_big':ras1,'Diff_big':ras-ras1,'Train_low':ras2,'Test_low':ras22,'Diff_low':ras2-ras22},name='AdaBoostClassifier'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki dla danych o dużej liczebności cech są odpowiednio wyższy i niższy dla danych treningowych i testowych w porównaniu z danymi o niskiej liczebności cech. Zbyt duże dopasowanie występuje dla danych o dużej liczebności cech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_big</th>\n",
       "      <th>Test_big</th>\n",
       "      <th>Diff_big</th>\n",
       "      <th>Train_low</th>\n",
       "      <th>Test_low</th>\n",
       "      <th>Diff_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.856239</td>\n",
       "      <td>0.776741</td>\n",
       "      <td>0.079498</td>\n",
       "      <td>0.816719</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.015395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.781744</td>\n",
       "      <td>0.778345</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.782162</td>\n",
       "      <td>0.779008</td>\n",
       "      <td>0.003153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.858820</td>\n",
       "      <td>0.773021</td>\n",
       "      <td>0.085798</td>\n",
       "      <td>0.816719</td>\n",
       "      <td>0.801325</td>\n",
       "      <td>0.015395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.840673</td>\n",
       "      <td>0.775953</td>\n",
       "      <td>0.064720</td>\n",
       "      <td>0.816126</td>\n",
       "      <td>0.800108</td>\n",
       "      <td>0.016018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Train_big  Test_big  Diff_big  Train_low  \\\n",
       "RandomForestClassifier       0.856239  0.776741  0.079498   0.816719   \n",
       "LogisticRegression           0.781744  0.778345  0.003399   0.782162   \n",
       "GradientBoostingClassifier   0.858820  0.773021  0.085798   0.816719   \n",
       "AdaBoostClassifier           0.840673  0.775953  0.064720   0.816126   \n",
       "\n",
       "                            Test_low  Diff_low  \n",
       "RandomForestClassifier      0.801325  0.015395  \n",
       "LogisticRegression          0.779008  0.003153  \n",
       "GradientBoostingClassifier  0.801325  0.015395  \n",
       "AdaBoostClassifier          0.800108  0.016018  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Zadanie 8\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystkie algorytmy nie mają zbyt dużego dopasowania dla danych o niskiej liczebności cech. Różnica miedzy wynikami jest tutaj podobna. Pomijając LogisticRegression mają one także podobne wyniki dla obu zbiorów, gdzie LogisticRegression ma niższe wyniki dla obu zbiorów.<br>\n",
    "W przypadku danych danych o dużej liczebności cech wyniki już się bardziej różnią. Najwyższy wynik otrzymałam dla zbioru treningowego przy użyciu GradientBoostingClassifier, ale w tym przypadku otrzymałam też największą różnicę wartości wyników. Tylko w przypadku LogisticRegression nie jest widoczne zbyt duże dopasowanie, ale w tym przypadku otrzymałam też najgorszy wynik dla zbioru treningowego. <br>\n",
    "Wszystkie algorytmy dają generalnie podobne wyniki, najbardziej odbiega od nich LogisticRegression, który ma też najmniejsze różnice pomiędzy wynikami. Największe róznice moża zaobserwować w przypadku RandomForestClassifier i GradientBoostingClassifier.<br>\n",
    "<br>\n",
    "Zadanie 9<br>\n",
    "predict_proba przewiduje prawdopodobieństwo klasyfikacji zgodnie z każdą klasą, a predict przewiduje klasę z największym prawdopodobieństwem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py36",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
